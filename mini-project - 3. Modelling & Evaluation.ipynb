{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.special import inv_boxcox       # to use absolute value\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Read cleanest data\n",
    "data = pd.read_csv('fifa21_male2-post-exploration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_destroyer(data, target, max_threshold=0.95):\n",
    "    corr_data = data.corr()\n",
    "    corr_target = corr_data[target]\n",
    "    corr_data.drop(target, axis=1, inplace=True)\n",
    "    corr_data.drop(target, axis=0, inplace=True)\n",
    "    \n",
    "    column_no = corr_data.shape[0]\n",
    "    to_drop = []\n",
    "\n",
    "    for i in range(0, column_no):\n",
    "        for j in range(i + 1, column_no):\n",
    "            if corr_data.iloc[i, j] > max_threshold:\n",
    "                if corr_target.iloc[i] > corr_target.iloc[j]:\n",
    "                    to_drop.append(corr_data.columns[j])\n",
    "                else:                 \n",
    "                    to_drop.append(corr_data.columns[i])\n",
    "    \n",
    "    to_drop = list(set(to_drop)) # Get unique values\n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Modelling & Evaluation\n",
    "\n",
    "#### 3.1. Define normalizing & modelling functions\n",
    "\n",
    "##### 3.1.1. Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    num = df.select_dtypes(np.number)\n",
    "    transformer = MinMaxScaler().fit(num) \n",
    "    x_minmax = transformer.transform(num)\n",
    "    num_norm = pd.DataFrame(x_minmax, columns=num.columns)\n",
    "    return num_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.2. Box-Cox transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcox_transform(data):\n",
    "    numeric_cols = data.select_dtypes(np.number).columns\n",
    "    _ci = {column: None for column in numeric_cols}\n",
    "    for column in numeric_cols:\n",
    "        if len(data[column].unique()) < 10:\n",
    "            continue\n",
    "        else:\n",
    "            # since i know any columns should take negative numbers, to avoid -inf in df\n",
    "            data[column] = np.where(data[column]<=0, np.NAN, data[column]) \n",
    "            data[column] = data[column].fillna(data[column].median())\n",
    "            transformed_data, ci = stats.boxcox(data[column])\n",
    "            data[column] = transformed_data\n",
    "            _ci[column] = [ci] \n",
    "    return data, _ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.3. Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, threshold=1.5):\n",
    "    numerical = df.select_dtypes(np.number)\n",
    "    columns = numerical.columns\n",
    "    for column in columns:\n",
    "        if len(df[column].unique()) < 10:\n",
    "            continue\n",
    "        else:\n",
    "            upper = np.percentile(df[column], 75)\n",
    "            lower = np.percentile(df[column], 25)\n",
    "            iqr = upper - lower\n",
    "            upper_limit = upper + threshold * iqr\n",
    "            lower_limit = lower - threshold * iqr\n",
    "            df = df[(df[column]>lower_limit) & (df[column]<upper_limit)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.5. Encode categorical data (`get_dummies`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat(df):\n",
    "    cat = df.select_dtypes(np.object)\n",
    "    cat = pd.get_dummies(df, columns=df.columns, drop_first=True)\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.6. Concatenate numerical and categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_df(num, cat):\n",
    "    new_df = pd.concat([num, cat], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1.7. Running & evaluating the model\n",
    "\n",
    "Looking at the R2 score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df, target):\n",
    "    y = df[target]\n",
    "    X = df.drop(target, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    return r2, predictions, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the predictions versus the real data and analyzing the MSE, RMSE, and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing the Box-cox transformation\n",
    "def reversing(predictions, _ci, target):\n",
    "    predictions = inv_boxcox(predictions, _ci[target][0])\n",
    "    return predictions\n",
    "\n",
    "# Calculate the modified metrics\n",
    "def evaluate_model_2(y_test, predictions):\n",
    "    RMSE = mean_squared_error(y_test, predictions, squared=False)\n",
    "    MSE = mean_squared_error(y_test, predictions)\n",
    "    MAE = mean_absolute_error(y_test, predictions)\n",
    "    return print(\"RMSE =\", RMSE), print(\"MSE =\", MSE), print(\"MAE =\", MAE)\n",
    "\n",
    "# Create dataframe for visualising the differences between real and predicted values\n",
    "def diff_df(y_test, _ci, target, predictions):\n",
    "    results = pd.DataFrame()\n",
    "    results['true'] = inv_boxcox(y_test, _ci[target][0])\n",
    "    results['pred'] = predictions\n",
    "    results['diff'] = results.apply(lambda x: abs(x['true'] - x['pred']), axis=1)\n",
    "    results = results.sort_values('diff', ascending=False).head(20)\n",
    "    return results\n",
    "\n",
    "# Plot results for visual representation\n",
    "def we_like_to_see(results):\n",
    "    beautiful_graph = sns.regplot(results['true'], results['pred'])\n",
    "    return beautiful_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the R2 adjusted to check which features contribute to the R2 score:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Optimize model for the `overall_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe copy\n",
    "data_1 = data.copy()\n",
    "\n",
    "# Remove correlated data\n",
    "to_drop = corr_destroyer(data_1, target='overall_score')\n",
    "data_1.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "# 1. Remove outliers\n",
    "data_1 = remove_outliers(data_1)\n",
    "\n",
    "# 2. Box-Cox transform\n",
    "data_1, _ci_1 = boxcox_transform(data_1)\n",
    "\n",
    "# 3. Scale numerical data\n",
    "num_norm_1 = normalize_data(data_1)\n",
    "\n",
    "# 4. Encode categorical data\n",
    "cat_1 = encode_cat(data_1)\n",
    "\n",
    "# 5. Merge numerical & categorical data\n",
    "new_df_1 = new_df(num_norm_1, cat_1)\n",
    "\n",
    "# 6. Run regression\n",
    "r2_1, predictions_1, y_test_1 = regression(new_df_1, 'overall_score')\n",
    "print(r2_1)\n",
    "\n",
    "# 7. See the predictions\n",
    "predictions_1 = reversed(predictions_1)\n",
    "evaluate_model_2(y_test_1, predictions_1)\n",
    "results = diff_df(y_test_1, _ci_1, target='overall_score', predictions=predictions_1)\n",
    "we_like_to_see(results)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
